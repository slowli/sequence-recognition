misc.file=File: {0}
misc.class=Object in the file: {0}
misc.dataset=Dataset:\n{0}\n
misc.out_file=Output file: {0}
misc.in_files_n=Input files: [{0} file(s)]
misc.launchable_file=Launchable file: {0}
misc.order=Markov chain order: {0}
misc.fitness=fitness({0}) = {1}
misc.save=Saving progress to file {0}
misc.save_error=Error while saving progress: {0}
misc.n_processed={0} sequences processed
misc.mixture=Model mixture:\n{0}

# Environment
env.load_conf=Loaded configuration from file ''{0}''
env.e_load_conf=Error loading configuration: {0}
env.debug=Debug level: {0}
env.threads=Number of computing threads: {0}
env.locale=Locale: {0}
env.encoding=Output encoding: {0}

# Sequence utilities
set.tr.e_map=Invalid translation map: {0}

# Attributes
attr.ambiguous=Ambiguous field name: {0}
attr.not_supported=Field type not supported: {0}

# Test cases
test.no_alg=Attach algorithm first
test.alg=Recognition algorithm:\n{0}
test.train_set=Train set:\n{0}
test.control_set=Control set:\n{0}
test.load_error=Error reading saved recognition algorithm: {0}
test.skip_train=Skipping quality estimation on a training set
test.quality=Quality:\n{0}
test.repr=Quality estimation on {0} sequences ({1} processed)\n
test.cv_repr={0}-fold cross validation on {1} sequences ({2} processed in all runs)\n
test.mean_train=Mean training quality:\n{0}
test.mean_ctrl=Mean control quality:\n{0}
test.fold.train=Fold #{0} (training)
test.fold.ctrl=Fold #{0} (control)
test.key=Key: '.'={0} processed sequences; '?'=skipped sequence; 'S'=saving progress

# Quality object
q.not_recognized={0} sequence(s) not recognized
q.state=Quality for hidden state \"{0}\":

# Recognition algorithms
alg.class=Class: {0}
alg.chain=Markov chain: order={1}, dep. length={0}
alg.threads=Number of threads: {0}
alg.base=Base recognition algorithm:\n{0}
alg.validate_cds=Validate CDS length to make it divisible by 3: {0}
alg.approx=Approximation type: {0}, minimal chain order: {1}
alg.algs_n=Number of constituent algorithms: {0}

ua.kiev.icyb.bio.alg.ThreadedAlgorithm=Wrapper algorithm for multi-threaded \
	hidden sequence recognition
ua.kiev.icyb.bio.alg.ViterbiAlgorithm=Recognition algorithm based on the max likelihood principle \
	with a Markov chain as the probabilistic model
ua.kiev.icyb.bio.alg.GeneViterbiAlgorithm=Recognition algorithm based on the max likelihood principle \
	with a Markov chain as the probabilistic model (modification for gene fragment recognition)
ua.kiev.icyb.bio.alg.FallthruAlgorithm=Recognition algorithm with approximation of unknown probabilities
ua.kiev.icyb.bio.alg.comp.PriorityCompAlgorithm=Recognition algorithm that uses priority voting \
	among several algorithms
ua.kiev.icyb.bio.alg.comp.SwitchAlgorithm=Composition of recognition algorithms with exclusive \
	competence regions of constituents
ua.kiev.icyb.bio.alg.comp.CompSwitchAlgorithm=Composition of recognition algorithms with exclusive \
	competence regions of constituents. \
	Competence regions are determined using a weighted mixture of Markov chains
ua.kiev.icyb.bio.alg.comp.TreeSwitchAlgorithm=Composition of recognition algorithms with exclusive \
	competence regions of constituents. \
	Competence regions are determined using a binary tree of predicates based on content of observed states

# Datasets
dataset.e_states=Mismatch in alphabets of observed and/or hidden states
dataset.e_length=Mismatch in the length of observed and hidden strings of states
dataset.default=Could not read the set; using default set with empty strings
dataset.e_name=Unknown dataset name: {0}
dataset.e_char=Invalid character in sequence: {0}
dataset.name=Dataset name(s): {0}
dataset.repr={0} sequences; observed states: {1}; hidden states: {2}
dataset.seq_len=Length of sequences: {0} total, {1} mean
dataset.str=[{0} sequences; {1}/{2}]
dataset.est=Estimates for dataset:\n{0}

# Feature add algorithm
add.bases=Base fragments: {0}
add.order=Order of Markov chains in the fitness function: {0}
add.max_size=Maximum size of fragment sets: {0}
add.combs=Number of optimal fragment sets with each size: {0}
add.curr_size=Current size of fragment sets: {0}
add.size=Size of fragment sets: {0}
add.sets_file=File to save sets to: {0}
add.process=Processing {0} combinations consisting of {1} fragments...
add.trimmed=Trimmed combinations: {0}
add.save_sets=Saving sets to file {0}
add.e_save_sets=Error saving sets: {0}

# Genetic algorithm
gen.generations=Number of generations: {0}
gen.crossovers=Number of crossovers for each organism: {0}
gen.mutations=Number of mutations for each organism: {0}
gen.max_size=Maximal size of the population: {0}
gen.mutation_p=Probability of an atomic mutation: {0}
gen.weak_cache=Use cache with weak references for keys: {0}
gen.init_pop=Initial population: {0} x {1}
gen.curr_gen=Index of the current generation: {0}
gen.curr_pop=Current population: {0} x {1}
gen.generation=Generation #{0}
gen.cache=Cache: fitness function for {0} organisms
gen.pop_size=Population size: {0}
gen.new_pop_size=Population size after adding mutations and crossovers: {0}
gen.filter=Filtering population by fitness function...
gen.tasks=Calculating fitness for {0} organisms ({1} already calculated, including {2} cached)
gen.save_pop=Saving current population to file {0}
gen.e_save_pop=Error saving population: {0}

# Genetic algorithm for rules
gen.trim_dist=Hamming distance used to trim close sets: {0}
gen.after_trim=Population size after removing close sets: {0}

# EM algorithm
em.max_models=Maximal number of models in the mixture: {0}
em.min_models=Minimal number of models in the mixture: {0}
em.min_weight=Minimal weight of a model: {0}
em.stochastic=Use stochastic modification of the maximization step: {0}
em.iterations=Number of iterations: {0}
em.template=Template for saving mixtures: {0}
em.sel_method=Method for selecting bad samples: {0}
em.offsets=Offsets when selecting bad samples: by index = {0}, by value = {1}
em.e_step=Step #{0} - expectation
em.m_step=Step #{0} - maximization
em.alignments=Item alignments (confidence threshold = {0}): {1}
em.n_models=Number of models in the mixture: {0}
em.weights=Weights of models in the mixture: {0}
em.chain=Chains in the mixture:\n{0}
em.save_comp=Saving mixture to file {0}
em.save_comp_error=Error saving mixture: {0}
em.add=Adding new component ({0} samples) with weight {1}
em.remove=Removing model #{0} with weight {1}
em.bad_search=Searching for bad samples...
em.bad_found={0} bad samples found

# Tree generation algorithm
tree.rules=Final number of rules in the tree: {0} 
tree.tree=Partition tree:\n{0}
tree.order=Order of Markov chains in the fitness function: {0}
tree.percentages=Percentages of set size to use to create rules: {0}
tree.min_part_size=Minimal size of a part: {0}
tree.bases=Fragment sets tried for content rules: {0}
tree.tree_file=File to save tree to: {0}
tree.part=Considering part {0}/{1} of the current partition
tree.infer=Inferring rules
tree.rule={0}: {1} samples
tree.small_set={0} - subset too small
tree.opt_rule=Optimal rule for part #{0}: {1} with fitness = {2}
tree.g_opt_rule=Global optimal rule: {1} with fitness = {2}, splitting part #{0}
tree.new_part=Created new part: {0}/{1} sequences ({2,number,percent}).
tree.no_rules=(no rules)
tree.repr_rule={0}: Split part #{1} according to rule {2}
tree.save_tree=Saving predicate tree into file {0}
tree.e_save_tree=Error saving the predicate tree: {0}

# Tasks
tasks.name=Task name: {0}
tasks.description=Description:\n{0}
tasks.args=Arguments:
tasks.class_not_found=Class container for tasks not found: {0}
tasks.no_descr=(no task description)
tasks.no_args=\tNo arguments accepted
tasks.not_found=Task not found: {0}

# Specific tasks
task.list=Lists all available tasks.

task.help=Prints help on the specified task.
task.help.0=identifier of a task

task.attr=Prints the values of all fields of a serialized objects and allows to change them.
task.attr.0=name of the file with a serialized object
task.attr.1=(optional; list) names of fields to change and their new values separated by '='. \
	Field names may contain the declaring class in order to solve ambiguities. 

task.print=Prints text representation of a serialized object.
task.print.0=name of the file containing a serialized object that implements Representable interface

task.launch=Launches an algorithm with the saved state.
task.launch.0=name of the file containing the serialized algorithm state

task.set.merge=Merges two or more sequence sets and saves the result.
task.set.merge.0=destination file
task.set.merge.1=list of files containing sequence sets to merge
task.set.merge.load=Loading set from the file {0}...
task.set.merge.add=Adding set {0}...
task.set.merge.save=Saving the resulting set...

task.set.tr=Translates observed and/or hidden states in a dataset.
task.set.tr.0=file containing input sequence set
task.set.tr.1=destination file
task.set.tr.2=translation map of observed states in the format '<src>:<dest>' where \
	<src> and <dest> are strings with the same length denoting source and corresponding \
	transformed states
task.set.tr.3=translation map of hidden states
task.set.tr.out=Transformed dataset:\n{0}
task.set.tr.save=Saving the transformed set...

task.quality=Estimates quality of a recognition algorithm trained on a certain dataset.
task.quality.0=dataset(s) to use for training
task.quality.1=dataset(s) to use for control
task.quality.2=order of the Markov chain to use with the alogrithm
task.quality.3=file to save testing results

task.viterbi.cv=Performs cross-validation using a hidden sequence recognition algorithm based \
	on dynamic programming.
task.viterbi.cv.0=dataset(s) to use
task.viterbi.cv.1=order of the Markov chain to use with the alogrithm
task.viterbi.cv.2=file to save testing results

task.approx.cv=Performs cross-validation using a recognition algorithm with approximation \
	of unknown probabilities.
task.approx.cv.0=dataset(s) to use
task.approx.cv.1=approximation strategy (one of 'priority', 'mean', 'first', or 'fixed')
task.approx.cv.2=maximal and minimal Markov chain orders separated with a dash '-'
task.approx.cv.3=file to save testing results

task.em.inc=Runs the EM algorithm for sequences with the incremental addition of probabilistic models.
task.em.inc.0=dataset(s) to use
task.em.inc.1=order of Markov chains in the mixture
task.em.inc.2=target number of models in the mixture
task.em.inc.3=template for saving generated chain mixtures. \
	'{n}' is replaced with the number of chains in the mixture; \
	'{i}' is replaced with the iteration of the algorithm
task.em.inc.4=file for saving algorithm progress

task.em.dec=Runs the EM algorithm for sequences with the incremental removal of probabilistic models.
task.em.dec.0=dataset(s) to use
task.em.dec.1=order of Markov chains
task.em.dec.2=initial number of models in the mixture; the models are trained \
	on random parts of the set
task.em.dec.3=target number of models in the mixture
task.em.dec.4=template for saving generated chain mixtures. \
	'{n}' is replaced with the number of chains in the mixture; \
	'{i}' is replaced with the iteration of the algorithm
task.em.dec.5=file for saving the algorithm progress

task.switch.cv=Performs cross-validation with the composition of recognition algorithms that uses model mixtures.
task.switch.cv.0=dataset(s) to use
task.switch.cv.1=method to determine competence regions ('classes' to use class markers or 'mixture' to use model mixture)
task.switch.cv.2=file that defines competence regions (space-separated class markers or serialized mixture, depending on the previous argument)
task.switch.cv.3=order of the Markov chain to use with the alogrithm
task.switch.cv.4=file to save testing results

task.features=Prints the table of real-value features for sequences in the supplied set. \
	Features are calculated as all conditional probabilities within the observed parts of the sequences.
task.features.0=dataset(s) to use
task.features.1=output file to put features into
task.features.2=order of conditional probabilities (optional; default is 4)

task.mix.classes=Prints the index of a Markov chain in a mixture with the maximum posterior likelihood \
	for all samples in a certain set.
task.mix.classes.0=dataset(s) to use
task.mix.classes.1=name of the file with the mixture
task.mix.classes.2=name of the output file
task.mix.classes.out=Writing indices to the file ''{0}''...

task.mix.likelihood=Calculates the mean log likelihood for a set of sequences and one or more \
	Markov chain mixtures.
task.mix.likelihood.0=dataset(s) to use
task.mix.likelihood.1=name(s) of files with serialized mixtures
task.mix.likelihood.p=Mean logarithmic likelihood: {0}

task.tree.genetic=Runs genetic algorithm to find most effective fragment sets for use \
	in the tree generation algorithm.
task.tree.genetic.0=dataset(s) to use
task.tree.genetic.1=length of fragments in the sets
task.tree.genetic.2=template for output files containing fragment sets; \
	{i} in the template is replaced with the 1-based index of the generation
task.tree.genetic.3=file to save algorithm progress

task.tree.add=Runs incremental feature adding algorithm to find most effective fragment sets \
	for use in the tree generation algorithm.
task.tree.add.0=dataset(s) to use
task.tree.add.1=length of fragments in the sets
task.tree.add.2=output file for fragment sets (updated on each iteration of the algorithm)
task.tree.add.3=file to save algorithm progress

task.tree=Generates the optimal binary tree for splitting the space of observable sequences \
	into competence regions.
task.tree.0=dataset(s) to use
task.tree.1=either file containing fragment sets, or length of fragments in the sets \
	to consider all non-redundant fragment sets	
task.tree.2=number of rules in the tree
task.tree.3=destination file for the generated tree
task.tree.4=file to save algorithm progress

task.tree.cv=Performs cross-validation with the composition of recognition algorithms that uses a partition tree.
task.tree.cv.0=dataset(s) to use
task.tree.cv.1=file with the partition tree
task.tree.cv.2=order of Markov chains to use in the algorithm
task.tree.cv.3=number of rules in the tree to actively use
task.tree.cv.4=destination file for computation results